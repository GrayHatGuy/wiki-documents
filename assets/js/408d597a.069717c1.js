"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[46915],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>f});var r=t(67294);function _(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(Object(t),!0).forEach((function(n){_(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,r,_=function(e,n){if(null==e)return{};var t,r,_={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||(_[t]=e[t]);return _}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(_[t]=e[t])}return _}var o=r.createContext({}),l=function(e){var n=r.useContext(o),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},d=function(e){var n=l(e.components);return r.createElement(o.Provider,{value:n},e.children)},p="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},u=r.forwardRef((function(e,n){var t=e.components,_=e.mdxType,s=e.originalType,o=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=l(t),u=_,f=p["".concat(o,".").concat(u)]||p[u]||c[u]||s;return t?r.createElement(f,a(a({ref:n},d),{},{components:t})):r.createElement(f,a({ref:n},d))}));function f(e,n){var t=arguments,_=n&&n.mdxType;if("string"==typeof e||_){var s=t.length,a=new Array(s);a[0]=u;var i={};for(var o in n)hasOwnProperty.call(n,o)&&(i[o]=n[o]);i.originalType=e,i[p]="string"==typeof e?e:_,a[1]=i;for(var l=2;l<s;l++)a[l]=t[l];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},65579:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var r=t(87462),_=(t(67294),t(3905));const s={description:"ChatGPT with Indicator",title:"Indicator ChatGPT Application",keywords:["SenseCAP ChatGPT AI Prompt"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/Indicator_Application_ChatGPT",last_update:{date:"5/23/2023",author:"Thomas"}},a="Indicator ChatGPT Setup Guide",i={unversionedId:"Sensor/SenseCAP/SenseCAP_Indicator/Application/Open_AI_SenseCAP_Indicator/Indicator_Application_ChatGPT",id:"Sensor/SenseCAP/SenseCAP_Indicator/Application/Open_AI_SenseCAP_Indicator/Indicator_Application_ChatGPT",title:"Indicator ChatGPT Application",description:"ChatGPT with Indicator",source:"@site/docs/Sensor/SenseCAP/SenseCAP_Indicator/Application/Open_AI_SenseCAP_Indicator/Indicator_Application_ChatGPT.md",sourceDirName:"Sensor/SenseCAP/SenseCAP_Indicator/Application/Open_AI_SenseCAP_Indicator",slug:"/Indicator_Application_ChatGPT",permalink:"/Indicator_Application_ChatGPT",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/SenseCAP/SenseCAP_Indicator/Application/Open_AI_SenseCAP_Indicator/Indicator_Application_ChatGPT.md",tags:[],version:"current",lastUpdatedBy:"Thomas",lastUpdatedAt:16848e5,formattedLastUpdatedAt:"May 23, 2023",frontMatter:{description:"ChatGPT with Indicator",title:"Indicator ChatGPT Application",keywords:["SenseCAP ChatGPT AI Prompt"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/Indicator_Application_ChatGPT",last_update:{date:"5/23/2023",author:"Thomas"}},sidebar:"ProductSidebar",previous:{title:"Grove IIC",permalink:"/Indicator_RP2040_Grove_IIC"},next:{title:"Indicator DALL\xb7E Application",permalink:"/Indicator_Application_DALL\xb7E"}},o={},l=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"MVC (Model-View-Controller)",id:"mvc-model-view-controller",level:2},{value:"View",id:"view",level:3},{value:"Model",id:"model",level:2},{value:"Example Code",id:"example-code",level:2}],d={toc:l};function p(e){let{components:n,...t}=e;return(0,_.kt)("wrapper",(0,r.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,_.kt)("h1",{id:"indicator-chatgpt-setup-guide"},"Indicator ChatGPT Setup Guide"),(0,_.kt)("p",null,"On this page, we will guide you on how to organize the OpenAI Demo for quick addition, deletion, and modification of programs according to the provided BSP."),(0,_.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,_.kt)("ul",null,(0,_.kt)("li",{parentName:"ul"},"One SenseCAP Indicator"),(0,_.kt)("li",{parentName:"ul"},"The IDF toolchain installed on your computer")),(0,_.kt)("admonition",{type:"note"},(0,_.kt)("ul",{parentName:"admonition"},(0,_.kt)("li",{parentName:"ul"},"Want to know how to change the UI? -> ",(0,_.kt)("a",{parentName:"li",href:"/Indicator_How_to_Create_your_own_UI"},"How to Create your own UI")),(0,_.kt)("li",{parentName:"ul"},"Haven't installed toolchain? -> ",(0,_.kt)("a",{parentName:"li",href:"/Indicator_How_To_Flash_The_Default_Firmware"},"How_To_Flash_The_Default_Firmware")))),(0,_.kt)("p",null,"The following code snippet is the main code related to OpenAI startup. flowchart:\n",(0,_.kt)("img",{parentName:"p",src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/Indicator_openai_sys.png",alt:null})),(0,_.kt)("h2",{id:"mvc-model-view-controller"},"MVC (Model-View-Controller)"),(0,_.kt)("p",null,"The openai_demo is developed based on the MVC architecture.\nFrom the above workflow, it can be seen that this project is based on the MVC architecture."),(0,_.kt)("ul",null,(0,_.kt)("li",{parentName:"ul"},"View port: indicator_view_init();"),(0,_.kt)("li",{parentName:"ul"},"Model port: indicator_model_init();"),(0,_.kt)("li",{parentName:"ul"},"Controller port: indicator_controller_init();")),(0,_.kt)("h3",{id:"view"},"View"),(0,_.kt)("p",null,"In the View, various event-triggered signals are mainly processed, and LVGL is used for driving the display."),(0,_.kt)("admonition",{type:"note"},(0,_.kt)("p",{parentName:"admonition"},"If you want to quickly build the UI, you can use ",(0,_.kt)("a",{parentName:"p",href:"https://squareline.io/"},"SquareLine Studio"),", which is also used in our project. Use version 1.3.0.")),(0,_.kt)("h2",{id:"model"},"Model"),(0,_.kt)("p",null,"When the newly added indicator_openai.c with indicator_openai_init(); is placed into indicator_model_init(); and executed at the Model entry, various event triggering mechanisms within it will send requests to OpenAI, receive responses, and parse them for display on the screen through the View."),(0,_.kt)("p",null,"The following are the key functions and workflow of the Model (once the API Key is saved):"),(0,_.kt)("p",null,(0,_.kt)("img",{parentName:"p",src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/model_openai.png",alt:null})),(0,_.kt)("h2",{id:"example-code"},"Example Code"),(0,_.kt)("p",null,"To utilize the OpenAI service, we need to implement functions that can send requests to OpenAI, receive responses, and parse the JSON response. As depicted in the flowchart above, it has provided us with the necessary information."),(0,_.kt)("pre",null,(0,_.kt)("code",{parentName:"pre",className:"language-c"},"/* HTTPS Request & get Response*/\nstatic int chat_request(struct view_data_openai_request *p_req,\n                        struct view_data_openai_response *p_resp);\n/* Json Prase*/\nstatic int __chat_json_prase(const char *p_str, char *p_answer, char *p_err);\n")),(0,_.kt)("p",null,"In the ",(0,_.kt)("inlineCode",{parentName:"p"},"chat_request")," function of ",(0,_.kt)("inlineCode",{parentName:"p"},"indicator_openai.c"),", the ",(0,_.kt)("inlineCode",{parentName:"p"},"data_buf")," variable is employed to store both the prompt and data input. If you are familiar with HTTP, you will recognize that this function generates an HTTP request that encapsulates user-supplied data."),(0,_.kt)("pre",null,(0,_.kt)("code",{parentName:"pre",className:"language-c"},'#define WEB_SERVER "api.openai.com"\n#define WEB_PORT "443"\n\nstatic char *p_recv_buf;\nstatic size_t recv_buf_max_len;\n\nstatic char openai_api_key[52];\nstatic bool have_key = false;\nstatic int chat_request(struct view_data_openai_request *p_req,\n                        struct view_data_openai_response *p_resp)\n{\n    // store the request and data to be sent to the OpenAI API.\n    char request_buf[2048];\n    char data_buf[1536];\n\n    \n    int data_len = 0; // store the length of the data \n    int ret = 0;\n    int len = 0; //store the length of the request\n\n    memset(request_buf, 0, sizeof(request_buf));\n    memset(data_buf, 0, sizeof(data_buf));\n\n    data_len = sprintf(data_buf,\n                       "{\\"model\\":\\"gpt-3.5-turbo\\",\\"temperature\\":0.7, \\"messages\\":[{\\"role\\":"\n                       "\\"user\\",\\"content\\":\\"");\n                     \n    data_len += sprintf(data_buf + data_len, "%s", p_req->question); // user question\n\n    len += sprintf(request_buf + len, "POST /v1/chat/completions HTTP/1.0\\r\\n");\n    len += sprintf(request_buf + len, "Host: %s\\r\\n", WEB_SERVER);\n    len += sprintf(request_buf + len, "Connection: Close\\r\\n");\n    len += sprintf(request_buf + len, "Content-Type: application/json\\r\\n");\n    len += sprintf(request_buf + len, "Content-Length: %d\\r\\n", data_len);\n    len += sprintf(request_buf + len, "Authorization: Bearer %s\\r\\n",\n                   openai_api_key);\n    len += sprintf(request_buf + len, "\\r\\n");\n    len += sprintf(request_buf + len, "%s", data_buf);\n\n    memset(p_recv_buf, 0, recv_buf_max_len);\n    /*\n    sending an HTTP request to the server specified by WEB_SERVER and WEB_PORT, with the request data stored in request_buf and the length of the request data stored in len. \n    It then waits for a response from the server, which is stored in\n    p_recv_buf with a maximum length of recv_buf_max_len. The function mbedtls_send_then_recv is used to perform both the sending and receiving of data in a single call. If the function returns a negative value, it indicates an error has occurred.\n    */\n    ret = mbedtls_send_then_recv(WEB_SERVER, WEB_PORT, request_buf, len,\n                                 p_recv_buf, recv_buf_max_len, 100, NULL);\n\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "mbedtls request fail");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Request fail");\n        return -1;\n    }\n    char *p_json = strstr(p_recv_buf, "\\r\\n\\r\\n");\n    if (p_json == NULL)\n    {\n        ESP_LOGE(TAG, "Response format error");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Response format error");\n        return -1;\n    }\n    p_json += 4;\n    p_resp->p_answer = p_recv_buf + recv_buf_max_len / 2; // use p_recv_buf mem\n    /*\n    The chat_request() function sends a request to the OpenAI API for generating a chat response and parses the response to extract the answer and error message.\n    */\n    ret = __chat_json_prase(p_json, p_resp->p_answer, p_resp->err_msg);\n    if (ret != 0)\n    {\n        p_resp->ret = 0;\n        return -1;\n    }\n    p_resp->ret = 1;\n    return 0;\n}\n\n')),(0,_.kt)("p",null,"In this function, ",(0,_.kt)("inlineCode",{parentName:"p"},"mbedtls_send_then_recv")," is called to do the request and get method."),(0,_.kt)("p",null,(0,_.kt)("strong",{parentName:"p"},"Adding Prompt")),(0,_.kt)("blockquote",null,(0,_.kt)("p",{parentName:"blockquote"},"If you want to add prompt to your application, just add codes like that:")),(0,_.kt)("pre",null,(0,_.kt)("code",{parentName:"pre",className:"language-c"},'data_len += sprintf(data_buf + data_len, "Your are SenseCAP Indicator, developed by Seeed Studio, has been launched on April 20th, 2023.");\ndata_len += sprintf(data_buf + data_len, "You are a 4-inch touch screen driven by ESP32 and RP2040 dual-MCU,");\ndata_len += sprintf(data_buf + data_len, "and support Wi-Fi/BLE/LoRa communication.");\ndata_len += sprintf(data_buf + data_len, "You are a fully open-source powerful IoT development platform for developers.");\ndata_len += sprintf(data_buf + data_len, "You are on behalf of Seeed Studio to answer requests.");\ndata_len += sprintf(data_buf + data_len, "Each time your answer text should not exceed 100 words.");\ndata_len += sprintf(data_buf + data_len, "My first sentence is [");\ndata_len += sprintf(data_buf + data_len, "%s", p_req->question); // user input\ndata_len += sprintf(data_buf + data_len, "]");\ndata_len += sprintf(data_buf + data_len, "\\"}]}");\n')),(0,_.kt)("p",null,"To see the detail code, go to ",(0,_.kt)("a",{parentName:"p",href:"https://github.com/Seeed-Solution/SenseCAP_Indicator_ESP32/blob/82d02957dbc71d4c1549246e823fac4ead89bb42/examples/indicator_openai/main/model/indicator_openai.c"},"indicator_openaI.c \xb7 GitHub")),(0,_.kt)("pre",null,(0,_.kt)("code",{parentName:"pre",className:"language-c"},'#include "indicator_openai.h"\n#include "cJSON.h"\n#include "esp_http_client.h"\n#include "esp_tls.h"\n#include "freertos/semphr.h"\n\n#include "lwip/dns.h"\n#include "lwip/err.h"\n#include "lwip/netdb.h"\n#include "lwip/sockets.h"\n#include "lwip/sys.h"\n\n#include "esp_crt_bundle.h"\n#include "mbedtls/ctr_drbg.h"\n#include "mbedtls/entropy.h"\n#include "mbedtls/error.h"\n#include "mbedtls/esp_debug.h"\n#include "mbedtls/net_sockets.h"\n#include "mbedtls/platform.h"\n#include "mbedtls/ssl.h"\n#include "nvs.h"\n\nstruct indicator_openai\n{\n};\n\nstatic const char *TAG = "openai";\n\nstatic struct view_data_openai_request request;\nstatic struct view_data_openai_response response;\n\nstatic SemaphoreHandle_t __g_gpt_com_sem;\nstatic SemaphoreHandle_t __g_dalle_com_sem;\nstatic bool net_flag = false;\n\nstatic int request_st_update(int progress, const char* msg)\n{\n    struct view_data_openai_request_st  st;\n    st.progress = progress;\n    strcpy(st.state, msg);\n    esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_REQUEST_ST, &st, sizeof(st), portMAX_DELAY);\n}\n\nstatic int mbedtls_send_then_recv(char *p_server, char *p_port, char *p_tx,\n                                  size_t tx_len, char *p_rx, size_t rx_len,\n                                  int delay_ms, void(*p_read_cb)(uint8_t *p_data, int len))\n{\n    int ret, flags, len;\n    char buf[512];\n\n    mbedtls_entropy_context entropy;\n    mbedtls_ctr_drbg_context ctr_drbg;\n    mbedtls_ssl_context ssl;\n    mbedtls_x509_crt cacert;\n    mbedtls_ssl_config conf;\n    mbedtls_net_context server_fd;\n\n    memset(&entropy,0, sizeof(entropy) );\n    memset(&ctr_drbg,0, sizeof(ctr_drbg) );\n    memset(&ssl,0, sizeof(ssl) );\n    memset(&cacert,0, sizeof(cacert) );\n    memset(&conf,0, sizeof(conf) );\n    memset(&server_fd,0, sizeof(server_fd) );\n    \n    mbedtls_ssl_init(&ssl);\n    mbedtls_x509_crt_init(&cacert);\n    mbedtls_ctr_drbg_init(&ctr_drbg);\n    ESP_LOGI(TAG, "Seeding the random number generator");\n    mbedtls_ssl_config_init(&conf);\n    ESP_LOGI(TAG, "Initializing the entropy source...");\n    mbedtls_entropy_init(&entropy);\n    ESP_LOGI(TAG, "Initializing the ctr_drbg...");\n    if ((ret = mbedtls_ctr_drbg_seed(&ctr_drbg, mbedtls_entropy_func, &entropy,\n                                     NULL, 0)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ctr_drbg_seed returned %d", ret);\n        return -1;\n    }\n\n    ESP_LOGI(TAG, "Attaching the certificate bundle...");\n    ret = esp_crt_bundle_attach(&conf);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "esp_crt_bundle_attach returned -0x%x\\n\\n", -ret);\n        return -1;\n    }\n    ESP_LOGI(TAG, "Setting hostname for TLS session...");\n    if ((ret = mbedtls_ssl_set_hostname(&ssl, p_server)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_set_hostname returned -0x%x", -ret);\n        return -1;\n    }\n\n    ESP_LOGI(TAG, "Setting up the SSL/TLS structure...");\n    if ((ret = mbedtls_ssl_config_defaults(&conf, MBEDTLS_SSL_IS_CLIENT,\n                                           MBEDTLS_SSL_TRANSPORT_STREAM,\n                                           MBEDTLS_SSL_PRESET_DEFAULT)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_config_defaults returned %d", ret);\n        goto exit;\n    }\n\n    mbedtls_ssl_conf_authmode(&conf, MBEDTLS_SSL_VERIFY_OPTIONAL);\n    mbedtls_ssl_conf_ca_chain(&conf, &cacert, NULL);\n    mbedtls_ssl_conf_rng(&conf, mbedtls_ctr_drbg_random, &ctr_drbg);\n#ifdef CONFIG_MBEDTLS_DEBUG\n    mbedtls_esp_enable_debug_log(&conf, CONFIG_MBEDTLS_DEBUG_LEVEL);\n#endif\n\n#ifdef CONFIG_MBEDTLS_SSL_PROTO_TLS1_3\n    mbedtls_ssl_conf_min_version(&conf, MBEDTLS_SSL_MAJOR_VERSION_3,\n                                 MBEDTLS_SSL_MINOR_VERSION_4);\n    mbedtls_ssl_conf_max_version(&conf, MBEDTLS_SSL_MAJOR_VERSION_3,\n                                 MBEDTLS_SSL_MINOR_VERSION_4);\n#endif\n\n    if ((ret = mbedtls_ssl_setup(&ssl, &conf)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_setup returned -0x%x\\n\\n", -ret);\n        goto exit;\n    }\n\n    mbedtls_net_init(&server_fd);\n\n    ESP_LOGI(TAG, "Connecting to %s:%s...", p_server, p_port);\n\n    if ((ret = mbedtls_net_connect(&server_fd, p_server, p_port,\n                                   MBEDTLS_NET_PROTO_TCP)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_net_connect returned -%x", -ret);\n        goto exit;\n    }\n\n    ESP_LOGI(TAG, "Connected.");\n\n    mbedtls_ssl_set_bio(&ssl, &server_fd, mbedtls_net_send, mbedtls_net_recv,\n                        NULL);\n\n    ESP_LOGI(TAG, "Performing the SSL/TLS handshake...");\n\n    while ((ret = mbedtls_ssl_handshake(&ssl)) != 0)\n    {\n        if (ret != MBEDTLS_ERR_SSL_WANT_READ && ret != MBEDTLS_ERR_SSL_WANT_WRITE)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_handshake returned -0x%x", -ret);\n            goto exit;\n        }\n    }\n\n    ESP_LOGI(TAG, "Verifying peer X.509 certificate...");\n\n    if ((flags = mbedtls_ssl_get_verify_result(&ssl)) != 0)\n    {\n        /* In real life, we probably want to close connection if ret != 0 */\n        ESP_LOGW(TAG, "Failed to verify peer certificate!");\n        bzero(buf, sizeof(buf));\n        mbedtls_x509_crt_verify_info(buf, sizeof(buf), "  ! ", flags);\n        ESP_LOGW(TAG, "verification info: %s", buf);\n    }\n    else\n    {\n        ESP_LOGI(TAG, "Certificate verified.");\n    }\n\n    ESP_LOGI(TAG, "Cipher suite is %s", mbedtls_ssl_get_ciphersuite(&ssl));\n\n    ESP_LOGI(TAG, "Writing HTTP request\\r\\n%s", p_tx);\n\n    size_t written_bytes = 0;\n    do\n    {\n        ret = mbedtls_ssl_write(&ssl, (const unsigned char *)p_tx + written_bytes,\n                                tx_len - written_bytes);\n\n        if (ret >= 0)\n        {\n            ESP_LOGI(TAG, "%d bytes written", ret);\n            written_bytes += ret;\n        }\n        else if (ret != MBEDTLS_ERR_SSL_WANT_WRITE &&\n                 ret != MBEDTLS_ERR_SSL_WANT_READ)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_write returned -0x%x", -ret);\n            goto exit;\n        }\n    } while (written_bytes < tx_len);\n\n    if (delay_ms > 0)\n    {\n        vTaskDelay(delay_ms / portTICK_PERIOD_MS); // wait\n    }\n\n    ESP_LOGI(TAG, "Reading HTTP response..."); // HERE\uff01\uff01\uff01\n\n    size_t recv_len = 0;\n\n    do\n    {\n        ret = mbedtls_ssl_read(&ssl, (unsigned char *)(p_rx + recv_len), rx_len - recv_len);\n        ESP_LOGI(TAG, "mbedtls_ssl_read returned %d", ret);\n        if (ret == MBEDTLS_ERR_SSL_WANT_READ || ret == MBEDTLS_ERR_SSL_WANT_WRITE)\n            continue;\n\n        if (ret == MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY)\n        {\n            ret = 0;\n            break;\n        }\n        if (ret < 0)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_read returned -0x%x", -ret);\n            break;\n        }\n        if (ret == 0)\n        {\n            ESP_LOGI(TAG, "connection closed");\n            break;\n        }\n        len = ret;\n        if( p_read_cb != NULL ) {\n            p_read_cb(NULL, len);\n        }\n        recv_len += len;\n    } while (1);\n\n    ESP_LOGI(TAG, "recv total: %d bytes ", recv_len);\n\n    mbedtls_ssl_close_notify(&ssl);\nexit:\n    mbedtls_ssl_session_reset(&ssl);\n    mbedtls_net_free(&server_fd);\n\n    if (ret != 0)\n    {\n        mbedtls_strerror(ret, buf, 100);\n        ESP_LOGE(TAG, "Last error was: -0x%x - %s", -ret, buf);\n        return -1;\n    }\n\n    return recv_len;\n}\n\n#define WEB_SERVER "api.openai.com"\n#define WEB_PORT "443"\n\nstatic char *p_recv_buf;\nstatic size_t recv_buf_max_len;\n\nstatic char openai_api_key[52];\nstatic bool have_key = false;\n\nstatic int __chat_json_prase(const char *p_str, char *p_answer, char *p_err)\n{\n    int ret = 0;\n\n    cJSON *root = NULL;\n    cJSON *cjson_item = NULL;\n    cJSON *cjson_item1 = NULL;\n    cJSON *cjson_item2 = NULL;\n\n    root = cJSON_Parse(p_str);\n    if (root == NULL)\n    {\n        strcpy(p_err, "Parse json fail");\n        return -1;\n    }\n\n    cjson_item = cJSON_GetObjectItem(root, "error");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cjson_item, "message");\n        if (cjson_item1 != NULL && cjson_item1->valuestring != NULL)\n        {\n            strcpy(p_err, cjson_item1->valuestring);\n        }\n        cJSON_Delete(root);\n        return -1;\n    }\n\n    cjson_item = cJSON_GetObjectItem(root, "choices");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cJSON_GetArrayItem(cjson_item, 0), "message");\n\n        if (cjson_item1 != NULL)\n        {\n            cjson_item2 = cJSON_GetObjectItem(cjson_item1, "content");\n\n            if (cjson_item2 != NULL && cjson_item2->valuestring != NULL)\n            {\n                strcpy(p_answer, cjson_item2->valuestring);\n                cJSON_Delete(root);\n                return 0;\n            }\n        }\n    }\n    strcpy(p_err, "Not find answer");\n    return -1;\n}\n\nstatic int chat_request(struct view_data_openai_request *p_req,\n                        struct view_data_openai_response *p_resp)\n{\n    char request_buf[2048];\n    char data_buf[1536];\n\n    int data_len = 0;\n    int ret = 0;\n    int len = 0;\n\n    memset(request_buf, 0, sizeof(request_buf));\n    memset(data_buf, 0, sizeof(data_buf));\n\n    data_len = sprintf(data_buf,\n                       "{\\"model\\":\\"gpt-3.5-turbo\\",\\"temperature\\":0.7, \\"messages\\":[{\\"role\\":"\n                       "\\"user\\",\\"content\\":\\"");\n                     \n    data_len += sprintf(data_buf + data_len, "Your are SenseCAP Indicator, developed by Seeed Studio, has been launched on April 20th, 2023.");\n    data_len += sprintf(data_buf + data_len, "You are a 4-inch touch screen driven by ESP32 and RP2040 dual-MCU,");\n    data_len += sprintf(data_buf + data_len, "and support Wi-Fi/BLE/LoRa communication.");\n    data_len += sprintf(data_buf + data_len, "You are a fully open-source powerful IoT development platform for developers.");\n    data_len += sprintf(data_buf + data_len, "You are on behalf of Seeed Studio to answer requests.");\n    data_len += sprintf(data_buf + data_len, "Each time your answer text should not exceed 100 words.");\n    data_len += sprintf(data_buf + data_len, "My first sentence is [");\n    data_len += sprintf(data_buf + data_len, "%s", p_req->question);\n    data_len += sprintf(data_buf + data_len, "]");\n    data_len += sprintf(data_buf + data_len, "\\"}]}");\n\n    len += sprintf(request_buf + len, "POST /v1/chat/completions HTTP/1.0\\r\\n");\n    len += sprintf(request_buf + len, "Host: %s\\r\\n", WEB_SERVER);\n    len += sprintf(request_buf + len, "Connection: Close\\r\\n");\n    len += sprintf(request_buf + len, "Content-Type: application/json\\r\\n");\n    len += sprintf(request_buf + len, "Content-Length: %d\\r\\n", data_len);\n    len += sprintf(request_buf + len, "Authorization: Bearer %s\\r\\n",\n                   openai_api_key);\n    len += sprintf(request_buf + len, "\\r\\n");\n    len += sprintf(request_buf + len, "%s", data_buf);\n\n    memset(p_recv_buf, 0, recv_buf_max_len);\n    ret = mbedtls_send_then_recv(WEB_SERVER, WEB_PORT, request_buf, len,\n                                 p_recv_buf, recv_buf_max_len, 100, NULL);\n    ESP_LOGI(TAG, "mbedtls ret = %d", ret);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "mbedtls request fail");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Request fail");\n        return -1;\n    }\n    ESP_LOGI(TAG, "Starting using strstr");\n    char *p_json = strstr(p_recv_buf, "\\r\\n\\r\\n");\n    if (p_json == NULL)\n    {\n        ESP_LOGE(TAG, "Response format error");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Response format error");\n        return -1;\n    }\n\n    p_json += 4;\n\n    p_resp->p_answer = p_recv_buf + recv_buf_max_len / 2; // use p_recv_buf mem\n\n    ret = __chat_json_prase(p_json, p_resp->p_answer, p_resp->err_msg);\n    if (ret != 0)\n    {\n        p_resp->ret = 0;\n        return -1;\n    }\n    p_resp->ret = 1;\n    return 0;\n}\n\nstatic void __openai_api_key_read(void)\n{\n    esp_err_t ret = 0;\n    int len = sizeof(openai_api_key);\n    ret = indicator_storage_read(OPENAI_API_KEY_STORAGE, (void *)openai_api_key, &len);\n    if (ret == ESP_OK && len == (sizeof(openai_api_key)))\n    {\n        have_key = true;\n        esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_ST, &have_key, sizeof(have_key), portMAX_DELAY);\n        ESP_LOGI(TAG, "openai_api_key read successful");\n    }\n    else\n    {\n        // err or not find\n        have_key = false;\n        esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_ST, &have_key, sizeof(have_key), portMAX_DELAY);\n        if (ret == ESP_ERR_NVS_NOT_FOUND)\n        {\n            ESP_LOGI(TAG, "openai_api_key not find");\n        }\n        else\n        {\n            ESP_LOGI(TAG, "openai_api_key read err:%d", ret);\n        }\n    }\n}\n\nstatic int __openai_init()\n{\n    recv_buf_max_len = 1024 * 1024;\n    p_recv_buf = malloc(recv_buf_max_len); // from psram\n    if (p_recv_buf == NULL)\n    {\n        ESP_LOGE(TAG, "malloc %s bytes fail!", recv_buf_max_len);\n    }\n}\n\nstatic void __indicator_openai_task(void *p_arg)\n{\n    int ret = 0;\n    while (1) {\n        if (net_flag) {\n            if (xSemaphoreTake(__g_gpt_com_sem, pdMS_TO_TICKS(100)) == pdTRUE) {\n                ESP_LOGI(TAG, "--\x3e chat request: %s", request.question);\n                memset(&response, 0, sizeof(response));\n                request_st_update(99, "Request..."); \n                ret = chat_request(&request, &response);\n                if (ret != 0) {\n                    ESP_LOGE(TAG, "reuest fail: %d, err_msg:%s", response.ret, response.err_msg);\n                    request_st_update(100, "Reuest fail");\n                } else {\n                    ESP_LOGI(TAG, "<-- response:%s", response.p_answer);\n                    request_st_update(100, "Done");\n                }\n                // vTaskDelay(pdMS_TO_TICKS(1000));\n                esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_CHATGPT_RESPONSE, &response, sizeof(response), portMAX_DELAY);\n            }\n\n            if (xSemaphoreTake(__g_dalle_com_sem, pdMS_TO_TICKS(100)) == pdTRUE)\n            {\n                ESP_LOGI(TAG, "--\x3e dell\xb7e request: %s", request.question);\n                memset(&response, 0, sizeof(response));\n                request_st_update(10, "Request...");\n                ret = image_request(&request, &response);\n                if (ret != 0) {\n                    ESP_LOGE(TAG, "reuest fail: %d, err_msg:%s", response.ret, response.err_msg);\n                    request_st_update(100, "Reuest fail");\n                } else {\n                    // ESP_LOGI(TAG, "<-- response:%s", response.p_answer);\n                    request_st_update(100, "Done");\n                }\n                esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_DALLE_RESPONSE, &response, sizeof(response), portMAX_DELAY);\n            }\n        }\n        vTaskDelay(pdMS_TO_TICKS(1000));\n    }\n}\n\nstatic void __view_event_handler(void *handler_args, esp_event_base_t base,\n                                 int32_t id, void *event_data)\n{\n    switch (id)\n    {\n        case VIEW_EVENT_WIFI_ST:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_WIFI_ST");\n            struct view_data_wifi_st *p_st = (struct view_data_wifi_st *)event_data;\n            if (p_st->is_network)\n            {\n                net_flag = true;\n            }\n            else\n            {\n                net_flag = false;\n            }\n            break;\n        }\n        case VIEW_EVENT_CHATGPT_REQUEST:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_CHATGPT_REQUEST");\n            struct view_data_openai_request *p_req = (struct view_data_openai_request *)event_data;\n            memcpy(&request,p_req, sizeof(request));\n            request_st_update(0, "ready");\n            xSemaphoreGive(__g_gpt_com_sem);\n            break;\n        }\n        case VIEW_EVENT_OPENAI_API_KEY_READ:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_OPENAI_API_KEY_READ");\n            __openai_api_key_read();\n            break;  \n        }\n        default:\n            break;\n    }\n}\n\nint indicator_openai_init(void)\n{\n    __g_gpt_com_sem = xSemaphoreCreateBinary();\n    __g_dalle_com_sem = xSemaphoreCreateBinary();\n\n    __openai_api_key_read();\n    __openai_init();\n    ESP_ERROR_CHECK(esp_event_handler_instance_register_with(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_WIFI_ST, __view_event_handler, NULL, NULL));\n\nESP_ERROR_CHECK(esp_event_handler_instance_register_with(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_CHATGPT_REQUEST, __view_event_handler, NULL, NULL));\n   \n   ESP_ERROR_CHECK(esp_event_handler_instance_register_with(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_API_KEY_READ, __view_event_handler, NULL, NULL));\n\n    xTaskCreate(&__indicator_openai_task, "__indicator_openai_task", 1024 * 10, NULL, 10, NULL);\n}\n \n')),(0,_.kt)("h1",{id:"resource"},"Resource"),(0,_.kt)("ul",null,(0,_.kt)("li",{parentName:"ul"},(0,_.kt)("a",{parentName:"li",href:"https://github.com/Seeed-Solution/SenseCAP_Indicator_ESP32/tree/82d02957dbc71d4c1549246e823fac4ead89bb42/examples/indicator_openai"},"Indicator OpenAI Demo \xb7 GitHub")),(0,_.kt)("li",{parentName:"ul"},"The actual effect: ",(0,_.kt)("a",{parentName:"li",href:"/Indicator_Get_Started_ChatGPT"},"ChatGPT_Indicator"))),(0,_.kt)("h1",{id:"tech-support"},(0,_.kt)("strong",{parentName:"h1"},"Tech Support")),(0,_.kt)("p",null,"Don't worry, we've got you covered! Please visit our ",(0,_.kt)("a",{parentName:"p",href:"https://discord.gg/cPpeuQMM"},"Seeed Official Discord Channel")," to ask your questions! "),(0,_.kt)("p",null,"If you have large order or customization requirement, please contact ",(0,_.kt)("a",{parentName:"p",href:"mailto:iot@seeed.cc"},"iot@seeed.cc")))}p.isMDXComponent=!0}}]);